# TourTheImi Function

### Description:

TourTheImi computes the one‐step transition probability matrix for an imitation‐based evolutionary process in a finite population playing an iterated game. Given a current population state (counts of each strategy), it evaluates expected payoffs against all other individuals, identifies the set of best‐performing strategies, and models one individual switching (“imitating”) to one of these best strategies. Repeating this over all possible states yields the full Markov transition matrix P.

### Syntax:

```matlab
[POP, BST, FIT] = TourTheImi(B, Strategies, POP0, K, T, J)
```

### Inputs:

- B (2×2 numeric matrix): Payoff matrix where rows/columns correspond to cooperation ('C') or defection ('D') moves.

  - B(1,1): Reward for mutual cooperation.

  - B(1,2): Sucker’s payoff (cooperate vs. defect).

  - B(2,1): Temptation payoff (defect vs. cooperate).

  - B(2,2): Punishment for mutual defection.

- Strategies (1×S cell array): Function handles or names of S strategy functions, each accepting a 2-column history matrix and returning a move ('C' or 'D').

- POP0 (1×S numeric vector): Initial counts of each strategy in the population.

- K (scalar integer): Number of individuals converted to the best strategy each generation.

- T (scalar integer): Number of repeated rounds per pairwise match.

- J (scalar integer): Number of generations (iterations) to simulate.

### Output:

- P (S×S numeric matrix): Transition probability matrix over all possible population states.

  - S = number of distinct population states (size of states, generated by generateStates_alt).

  - Entry P(i,j) is the probability of moving from state i to state j in one imitation event.

### Detailed Behavior:

1. **State Generation**  
   Enumerates all nonnegative integer partitions of N into M bins (strategy counts) via generateStates_alt, forming an S×M matrix states.

2. **Payoff Computation**  
   For each state s, expected payoff of each focal strategy i is computed by summing pairwise scores against every other individual in the population (excluding self‐play correction) using computePayoffs.

3. **Best Strategy Identification**  
   The set of strategies achieving the maximal payoff in that state is found by findBestStrategies.

4. **Transition Probabilities**  
   For each strategy type from that has at least one individual in s, and for each best strategy to, one individual of type from imitates strategy to. The new state s_new differs by −1 in count of from and +1 in count of to.
   The probability of selecting the individual of type from is s(from)/N, and the probability of choosing among best strategies is 1/length(best_strats). These contributions are accumulated into P(i, idx_new).

### Example:

```matlab
Strategies = {'AllC', 'AllD', 'Grim'};
POP0 = [1, 1, 1];
J = 10;
K = 1;
T = 100;
B = [3, 0; 5, 1];

P = TourTheImi(B, Strategies, POP0, K, T, J);

mc = dtmc(P);

figure;
graphplot(mc)
```
